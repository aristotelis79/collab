{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "cm9GN4WNtK_d",
        "kQb9SHI-tNyH",
        "-AKKIC9AzDWP",
        "Ai85jC1HzGSI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1585b2d6019c45bf9f4dd9497167883e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72368086d2bb43b7bfc0a574b9e409ef",
              "IPY_MODEL_17d11dcc99c842c1af438d26bc8eb3e5",
              "IPY_MODEL_97787536371f4ca388dda3f3508e30d6"
            ],
            "layout": "IPY_MODEL_aa6f7082ec4a411f963b8e2f8a7c2152"
          }
        },
        "72368086d2bb43b7bfc0a574b9e409ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b95834163694a62bc55fce4353957a7",
            "placeholder": "​",
            "style": "IPY_MODEL_86ec4aed9d5745859eaf37559babf8bf",
            "value": "Map: 100%"
          }
        },
        "17d11dcc99c842c1af438d26bc8eb3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff76fdb2bdd4ca4a75858cbfbd5b7b1",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b587a2788754f17b3a15ad5a1a9e455",
            "value": 25000
          }
        },
        "97787536371f4ca388dda3f3508e30d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486485b4a6ff4dadb50138c15868e323",
            "placeholder": "​",
            "style": "IPY_MODEL_ceabdf81439148948297e9c64ce91300",
            "value": " 25000/25000 [00:22&lt;00:00, 1090.17 examples/s]"
          }
        },
        "aa6f7082ec4a411f963b8e2f8a7c2152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b95834163694a62bc55fce4353957a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ec4aed9d5745859eaf37559babf8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eff76fdb2bdd4ca4a75858cbfbd5b7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b587a2788754f17b3a15ad5a1a9e455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "486485b4a6ff4dadb50138c15868e323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceabdf81439148948297e9c64ce91300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aristotelis79/collab/blob/main/nlp-transformers/2_TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Transformers with HuggingFace\n",
        "\n",
        "© Data Trainers LLC. GPL v 3.0.\n",
        "\n",
        "Author: Axel Sirota"
      ],
      "metadata": {
        "id": "gzf37X_XizQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace is a company with a heavy open source philosophy that makes transformers readily available so you don't have to do what we did before for every application."
      ],
      "metadata": {
        "id": "5MjeyOLmr-WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep"
      ],
      "metadata": {
        "id": "cm9GN4WNtK_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets evaluate transformers transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "C9BTEOu0PerV",
        "outputId": "21051c49-c2b2-42d3-e3eb-cb93ffc6037d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf_keras # Keras 2\n",
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "9fZfvKkv84rT",
        "outputId": "fc2776e2-f6d5-4b31-8176-1550b0400869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.10/dist-packages (2.16.0)\n",
            "Requirement already satisfied: tensorflow<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tf_keras) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf_keras) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0fpgYwAtNO2T"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import keras.backend as K\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "TRACE = False\n",
        "PATIENCE = 2\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def set_seeds_and_trace():\n",
        "  os.environ['PYTHONHASHSEED'] = '0'\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  random.seed(42)\n",
        "  if TRACE:\n",
        "    tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "def set_session_with_gpus_and_cores():\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
        "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "  sess = tf.compat.v1.Session(config=config)\n",
        "  tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "set_seeds_and_trace()\n",
        "set_session_with_gpus_and_cores()\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing and loading the dataset\n",
        "\n",
        "In HuggingFace there are many models, and each has its own tokenizer. Lucky for us there is a class `AutoTokenizer` that does the heavylifting after we provide a checkpoint"
      ],
      "metadata": {
        "id": "kQb9SHI-tNyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "raw_datasets = load_dataset(\"imdb\")  # loads dataset raw\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "gkzGKLjN-T9k",
        "outputId": "f6645f54-a806-4fcc-e7c4-e8571bfe8867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice it is a dict object with the train, test, and unsupervised datasets to play around"
      ],
      "metadata": {
        "id": "CnDCHDZ7trYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'][0]  # Let's see the first review"
      ],
      "metadata": {
        "id": "1Q13wuHGtqu4",
        "outputId": "f5cb0a38-cabd-4ff2-805e-a73e253c476a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we know if it's positive or negative from label=0?"
      ],
      "metadata": {
        "id": "hz7V6Iw1uEJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'].features"
      ],
      "metadata": {
        "id": "HgQQCHo5t99k",
        "outputId": "903cade3-6b31-440d-d2bf-5d4d3c2925f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There it is, within features we see that the index 0 is **Negative**\n",
        "\n",
        "Now to tokenise the dataset we need to load the proper tokenizer for the model we care about. And the we are goin to apply it everywhere!\n",
        "\n",
        "After this step the tokenizer converts the text into a Tensor of ids, each representing a diferent word in the BERT vocabulary"
      ],
      "metadata": {
        "id": "C7p9f6uYuDNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    # We are using the BERT tokenizer, specifying to PAD until the end,\n",
        "    # truncate if either 128 elements are met or the maximum from the model, which you get from the model card\n",
        "\n",
        "    return tokenizer(example[\"text\"], padding=True, truncation=True, max_length=128)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "zZ0eyz_bswnn",
        "outputId": "2a0c3972-1a99-445a-d547-2129fbde9e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1585b2d6019c45bf9f4dd9497167883e",
            "72368086d2bb43b7bfc0a574b9e409ef",
            "17d11dcc99c842c1af438d26bc8eb3e5",
            "97787536371f4ca388dda3f3508e30d6",
            "aa6f7082ec4a411f963b8e2f8a7c2152",
            "9b95834163694a62bc55fce4353957a7",
            "86ec4aed9d5745859eaf37559babf8bf",
            "eff76fdb2bdd4ca4a75858cbfbd5b7b1",
            "3b587a2788754f17b3a15ad5a1a9e455",
            "486485b4a6ff4dadb50138c15868e323",
            "ceabdf81439148948297e9c64ce91300"
          ]
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1585b2d6019c45bf9f4dd9497167883e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it worked!"
      ],
      "metadata": {
        "id": "oSt_kIFKvKwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train'][0]['text']"
      ],
      "metadata": {
        "id": "oM3_SxEHaYpg",
        "outputId": "1c2b4e93-77fe-41fb-9e89-1f5d91d06049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(tokenized_datasets['train'][0]['text'])"
      ],
      "metadata": {
        "id": "tu6DT9ARvqeL",
        "outputId": "940f65c2-35f3-4241-c6c5-89db822ab09f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer from BERT (well DistillBERT) converts each word into its ID according to *its* vocabulary. And notice the masking says we haven't been truncated. What we will do know is do this for all data and convert it into a TF Datasets object (which Keras accepts)"
      ],
      "metadata": {
        "id": "db-I6E5EvymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    columns=['input_ids'],\n",
        "    label_cols=[\"label\"],\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "tf_validation_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "    columns=['input_ids'],\n",
        "    label_cols=[\"label\"],\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "_BkOcOV3YM-i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in tf_train_dataset.take(1):\n",
        "  print(f' inputs: {inputs.shape}, labels: {labels.shape}')\n"
      ],
      "metadata": {
        "id": "fm-TbT_LwMaK",
        "outputId": "b22ce204-29e3-4f1f-86e7-d50cc27b89ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " inputs: (256, 128), labels: (256,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the model and prepare for training"
      ],
      "metadata": {
        "id": "-AKKIC9AzDWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's download the model. It is very important you use the class that starts with `TFAutoModel`. There are auto models for most tasks, so you don't have to manually add the header, for example the `TFAutoModelForSequenceClassification` adds a Dense layer (WITHOUT SOFTMAX) to do the classification"
      ],
      "metadata": {
        "id": "B5NK3y0Kvy9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "UQ1RBW49vzi2",
        "outputId": "40b1d346-b9ec-48e3-b4aa-17afd390899e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "batch_size = BATCH_SIZE\n",
        "num_epochs = EPOCHS\n",
        "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
        "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
        "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5, end_learning_rate=1e-8, decay_steps=num_train_steps\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate=lr_scheduler)"
      ],
      "metadata": {
        "id": "QpdCdwVVc7av"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # VERY important that HuggingFace models output logits\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "v7wxa25Yc7l2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=PATIENCE)\n"
      ],
      "metadata": {
        "id": "RsRSw2GufIfh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5_4l0JM6e7tx",
        "outputId": "adc72a30-8944-496d-fc72-f04d348445a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMa  multiple                  66362880  \n",
            " inLayer)                                                        \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        multiple                  0 (unused)\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66955010 (255.41 MB)\n",
            "Trainable params: 66955010 (255.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh no! We have too many parameters to train! Luckily in Keras is very easy to set some layers as not trainable"
      ],
      "metadata": {
        "id": "w0IY68FyxQ5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "2z7l4zzOglb5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "w-7KUG_qgxLA",
        "outputId": "8a71982b-4b57-4d07-c119-c26e0842a709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMa  multiple                  66362880  \n",
            " inLayer)                                                        \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        multiple                  0 (unused)\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66955010 (255.41 MB)\n",
            "Trainable params: 592130 (2.26 MB)\n",
            "Non-trainable params: 66362880 (253.15 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Voilá!*"
      ],
      "metadata": {
        "id": "2XwbQq6_xXjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "a5NEOuZkdJl2",
        "outputId": "2fbd4083-e8e4-44d0-ff09-ff930965b0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node tf_distil_bert_for_sequence_classification/distilbert/transformer/layer_._4/attention/Softmax defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-20-07ac9fd844d3>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1669, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1672, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 805, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 813, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 805, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 459, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 362, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 366, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 297, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 199, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 72, in stable_softmax\n\nOOM when allocating tensor with shape[256,12,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_distil_bert_for_sequence_classification/distilbert/transformer/layer_._4/attention/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_16408]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-07ac9fd844d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_validation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node tf_distil_bert_for_sequence_classification/distilbert/transformer/layer_._4/attention/Softmax defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-20-07ac9fd844d3>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1669, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1672, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 588, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 805, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 813, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 805, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 459, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 362, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 366, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 297, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 553, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 558, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1047, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__\n\n  File \"/tmp/__autograph_generated_files_snojvf.py\", line 34, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 199, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 72, in stable_softmax\n\nOOM when allocating tensor with shape[256,12,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_distil_bert_for_sequence_classification/distilbert/transformer/layer_._4/attention/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_16408]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a trained model that did transfer learning from DistillBERT"
      ],
      "metadata": {
        "id": "bh7F4SHfiXjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing it out!"
      ],
      "metadata": {
        "id": "Ai85jC1HzGSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer([\"This is the worst internet service provider\", \"Although most people say this is the worst, I like it\"], padding=True, truncation=True, max_length=128)"
      ],
      "metadata": {
        "id": "G4Tw4BGWdPbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "id": "seclxXEgivkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(tokens['input_ids'])"
      ],
      "metadata": {
        "id": "MFfLSI28i2IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the prediction where not probabilities but logits!"
      ],
      "metadata": {
        "id": "dptMVX4Yyz8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.softmax(model.predict(tokens['input_ids'])['logits'])"
      ],
      "metadata": {
        "id": "h_aQ5cWxkBqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.argmax(tf.math.softmax(model.predict(tokens['input_ids'])['logits']))"
      ],
      "metadata": {
        "id": "g07INFlujKAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the model was correct!!"
      ],
      "metadata": {
        "id": "xehvfI6Qy56b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(tf_validation_dataset)"
      ],
      "metadata": {
        "id": "vTev4jIXjwRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}